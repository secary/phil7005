# Assignment 2. PHIL 7005. Due 2 December.

You have two options here. If you really want to write on another topic and have a well worked out plan then please discuss with me.

## Option 1.  A 2000 word assignment on the following topic.

How should we explain the performance of AI systems on tasks designed to probe the nature of human psychology? 

Your answer should discuss at least 2 of the psychological capacities we covered in weeks 7-11. i.e. Language,Theory of Mind, Reasoning. Emotion, Self Awareness.

This is an essay question so clarity of structure is important. It must be organised as a coherent argument to a conclusion. I am looking for evidence that you have understood and can apply the ideas. Imagine that you are teaching the topic to a third year undergraduate and trying to explain your conclusion in a way that both gets across the necessary information, supports your argument, and shows awareness of and ability to deal with alternative arguments.

Clearly every key term needs clear definition and evidential or argumentative support.

## Option 2. Same structure as first assignment. i.e. 4 questions each approximately 500 words.

1. Can LLMs be self aware? What, if anything would be the difference between Turing self awareness and real self awareness. Does the nature of cognitive architecture make a difference to this issue? Why?

2. Does the performance of AI systems on so called Theory of Mind tasks suggest that they understand other minds?

3. Do LLMs understand grammatical concepts?

4. Can a disembodied system be genuinely intelligent? Why or why not?

## Reference list
### GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models
 Iman Mirzadeh† Keivan Alizadeh Hooman Shahrokhi∗  
 Oncel Tuzel Samy Bengio Mehrdad Farajtabar†  
 arXiv:2410.05229v1  [cs.LG]  7 Oct 2024  
 Apple  
 * 这篇论文由 Apple 团队撰写，探讨了大型语言模型（LLMs）在数学推理方面的表现及其局限性。通过 GSM-Symbolic 基准测试，研究揭示了即便是先进的语言模型也难以处理需要精细符号操作和复杂逻辑推理的数学问题。研究发现，这些模型在解决多步骤逻辑问题时常常失败，原因主要是模型缺乏对数学符号的本质理解和对长期逻辑链的保持能力。此项研究对理解 AI 在严格学科领域的应用提供了深刻见解，并对未来如何设计能够更好进行数学推理的模型提出了挑战。
 * 研究背景：在人工智能领域，数学推理一直是衡量智能系统复杂认知能力的重要方面。然而，即使是最先进的大型语言模型（LLMs），在处理需要精确逻辑和符号操作的数学任务时也显示出局限性。
* 研究方法：研究者通过新开发的 GSM-Symbolic 基准测试来评估不同 LLMs 的数学推理能力。这个基准专注于符号推理任务，如代数和几何问题，旨在分析模型在解决这些问题时的表现。
* 主要发现：研究发现，尽管 LLMs 在语言处理任务中表现出色，但在数学推理任务中，它们常常无法正确处理符号代换、执行准确的逻辑推理，或持续维持多步骤问题解决的逻辑链。
* 实际意义：这项研究表明，LLMs 在处理数学问题时的局限性可能源于它们基于统计学习的核心设计，缺乏对数学概念和原理的真正理解。

### Engineering empathy
 Emotion and self representation in artificial intelligence  
 * 该文献探索了在人工智能中设计并实现情感理解和自我表达能力的挑战和方法。作者讨论了如何通过各种技术手段（如情感计算、自然语言理解和生成）使机器更好地理解和模拟人类情感反应，以及这些技术在提升人机交互中的作用。此外，文章还涉及到自我意识在 AI 中的模拟尝试，探讨了如何通过增强学习和决策过程中的自我反馈机制来实现这一点。
 * 研究目的：探索如何在 AI 系统中设计和实现模拟人类情感和自我意识的能力，以提升机器的人际互动质量。
 * 技术方法：文章详细介绍了使用情感计算框架和自然语言处理技术来解析和模拟人类情感表达。此外，通过增强学习和自我调节机制，研究人员尝试在 AI 中培养初步的自我意识。
 * 关键挑战：尽管技术进步使 AI 能够在一定程度上模拟情感和自我表达，但真正的情感理解和自我意识仍是 AI 研究中的重大挑战，这涉及到复杂的认知和情感处理问题。
 * 应用前景：这种技术的进步预示着 AI 在未来能够更好地理解人类用户的情感需求，从而在教育、医疗和客户服务等领域发挥更大的作用。

### Dual-Process Theories of Higher Cognition: Advancing the Debate
 Jonathan St. B. T. Evans1 and Keith E. Stanovich2  
 1School of Psychology, University of Plymouth, England; and 2Department of Applied  Psychology and Human Development, University of Toronto, Ontario, Canada  
 * 这篇论文由 Jonathan St. B. T. Evans 和 Keith E. Stanovich 共同撰写，详细论述了双加工理论在高级认知研究中的应用。双加工理论区分了两种思维方式：直觉思维（快速、自动、无意识）和分析思维（慢、努力、意识形态）。文章评价了这一理论在解释人类决策、推理以及错误倾向方面的有效性，并讨论了其在认知心理学和相关领域中的争议和发展。
 * 理论基础：双加工理论区分了系统1（直觉思维）和系统2（分析思维），每种思维模式在不同的认知任务中起着不同的作用。
 * 研究贡献：文章评价了这一理论如何帮助理解人类在复杂决策、问题解决及其出错的原因，尤其是在高认知需求的任务中系统2如何介入。
 * 争议点：论文还讨论了双加工理论在心理学界的接受度，以及对该理论的一些批评，包括理论的界定不够明确和实证研究的限制。
 * 理论应用：作者探讨了如何将双加工理论应用于教育、认知疗法和人工智能等领域，以优化决策过程和认知策略。


###  Computational Neuroscience: From Biology to Cognition
 Randall C O’Reilly, University of Colorado, Boulder, Colorado, USA  
 Yuko Munakata, University of Denver, Colorado, USA  
 * 由 Randall C O’Reilly 和 Yuko Munakata 撰写的论文，深入介绍了计算神经科学如何将生物学原理应用于认知过程的模拟。这篇文章探讨了大脑的计算模型是如何帮助科学家们理解记忆、注意力和学习等认知功能的神经基础。通过计算模型，研究者能够更好地解释大脑活动如何转化为具体的认知行为。
 * 研究领域：计算神经科学是一个交叉学科领域，通过数学模型和计算方法来理解神经系统如何实现认知功能。
 * 主要内容：论文概述了几种主要的计算模型，如神经网络模型和动态系统模型，这些模型如何帮助科学家解释记忆、注意力、学习和决策等认知过程。
 * 科学意义：通过建立大脑活动的计算模型，研究人员能更好地理解认知疾病的神经基础，例如阿尔茨海默病和注意力缺陷超动症，并为治疗这些疾病提供新的方法。

### Modern language models refute Chomsky’s approach to language
 Steven T. Piantadosia,b  
 aUC Berkeley, Psychology bHelen Wills Neuroscience Institute  
 * Steven T. Piantadosi 在这篇文章中分析了现代语言模型如何挑战乔姆斯基的语言理论。论文指出，与乔姆斯基强调的天赋语言能力和普遍语法不同，现代语言模型显示出通过大规模数据学习和统计模式识别可以有效地处理和生成语言，这表明语言能力可能更多地依赖于统计学习而非内在的语法结构。
 * 论点核心：文章挑战了乔姆斯基关于语言天赋说和普遍语法的理论，强调现代语言模型如何显示出语言能力更多依赖于大规模数据的统计学习。
 * 理论对比：通过分析现代语言模型（如 GPT 和 BERT）在语言处理任务中的表现，作者提出语言能力可能并非内在的语法结构，而是通过大量语言输入的模式识别能力获得。
 * 理论影响：这种观点对语言学习理论和语言教育方法可能带来重大影响，促使学者和教育者重新考虑语言教学的方法和理论基础。

### Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT
 Received: 17 February 2023  
 Accepted: 5 September 2023  
 Published online: 5 October 2023  
 Check for updates  
 Thilo Hagendorff1, Sarah Fabi2 & Michal Kosinski 3  
 * Thilo Hagendorff 等人的研究分析了大型语言模型在模拟人类直觉行为和推理偏见方面的能力。该研究发现，尽管早期模型表现出与人类相似的行为和偏见，但在 ChatGPT 的开发中，这些特征被显著减少。文章讨论了 AI 设计中如何平衡模仿人类行为与避免人类错误倾向的挑战。
 * 研究背景：这篇论文研究了大型语言模型如何模拟人类的直觉行为和推理偏见，并特别观察这些特征在 ChatGPT 开发中的变化。
 * 研究发现：早期的大型语言模型（如 GPT-2 和 GPT-3）显示出能够复现人类的一些直觉偏见和推理方式。然而，随着 ChatGPT 的优化和进化，许多这样的人类行为特征被减少或消除，以求达到更中立和事实基础的输出。
 * 技术分析：研究分析了 ChatGPT 如何通过改进的训练过程和算法调整，减少偏见和误导性信息的生成，同时探讨了这种改变对 AI 可靠性和用户信任的正面影响。
 * 社会意义：文章讨论了在设计 AI 时平衡模拟人类行为与消除人类错误倾向的挑战，以及这对 AI 伦理和社会接受度的影响。

### Theory of Mind in Infants and Young Children: A Review
 Virginia Slaughter  
 School of Psychology, The University of Queensland  
 * Virginia Slaughter 的综述文章探讨了婴儿和幼儿如何发展心理理论能力，即理解其他人的信念、愿望和情感的能力。通过总结大量实验研究，作者说明了心理理论能力如何从非常年幼的儿童开始逐步发展，并探讨了这一能力的早期形成对儿童社交互动的重要性。
 * 研究领域：这篇综述文章聚焦于婴幼儿的心理理论（Theory of Mind，ToM）发展，即儿童如何学习理解他人的信念、愿望和情感。
 * 主要内容：文中总结了众多实验研究，展示了婴幼儿如何从仅几个月大开始展示对他人行为的预测能力，以及他们如何在三岁左右开始显示理解他人心理状态的更复杂能力。
 * 理论重要性：心理理论的发展对儿童的社交技能和情感发展至关重要，影响他们的同理心、冲突解决能力和更广泛的社交互动。
 * 实际应用：了解心理理论的早期发展可以帮助教育者和父母更好地支持儿童的社会情感学习，也为设计能模拟或理解人类社交动态的 AI 提供了见解。

### Being a Beast Machine: The Somatic Basis of Selfhood
 Anil K. Seth1,*and Manos Tsakiris2,3  
 * Anil K. Seth 和 Manos Tsakiris 的论文提出了自我意识的体感基础理论，即“野兽机器”概念。这篇文章探讨了身体感觉如何构成我们的身份感和主观体验的基础，从而挑战了传统上重视认知和心理构造的自我理论，强调了身体在形成和维持个体身份中的核心作用。
 * 理论提出：Anil K. Seth 和 Manos Tsakiris 探讨了自我意识的生物学基础，特别是他们提出的“野兽机器”概念，这是一种理论，认为自我意识主要源自我们对自己身体状态的感知和解释。
 * 主要论点：文章强调身体感觉（如感受到心跳、呼吸等）在形成个体的主观经验和自我感中的中心作用。这一观点与传统更侧重于认知和心理过程的自我理论形成对比。
 * 实证研究：论文引用了多项神经科学实验，展示了身体状态如何影响人们的情绪感知、决策和自我感知。
 * 实际影响：这种理解自我意识的方式对于认知科学、心理治疗乃至人工智能中模拟人类自我意识的尝试都有重要启示。